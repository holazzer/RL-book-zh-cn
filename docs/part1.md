## 第一部分 表格方法

在本书的这一部分中，我们以最简单的形式描述了强化学习算法的几乎所有核心​​思想：状态和动作空间足够小，可以将近似值函数表示为数组或表。在这种情况下，这些方法通常可以找到精确的解决方案，也就是说，它们通常可以精确地找到最优价值函数和最优策略。这与本书下一部分描述的近似方法形成对比，后者仅能找到近似解，但反过来可以有效地应用于更大的问题。

这一部分的第一章介绍了特殊情况下强化学习问题的解决方法，在这种情况下，只有一个状态，称为**摇臂赌博机问题(bandit problems)**。第二章介绍了本书其余部分将讨论的一般问题表述（有限的马尔可夫决策过程）及其主要思想，其中包括**Bellman方程**和**值函数**。接下来的三章描述了解决有限马尔可夫决策问题的方法的三个基本类别：动态规划，蒙特卡洛方法和时序差分学习。每种方法都有其优点和缺点。动态规划方法在数学上已经很好地开发，但是需要完整且准确的环境模型。蒙特卡洛方法不需要模型，概念上也很简单，但并不适合逐步进行增量计算。最后，时序差分算法不需要模型，而是完全增量的，但分析起来更复杂。这些方法的效率和收敛速度也不同。

最后两章介绍了如何将这三类方法结合起来以获得每种方法的最佳功能。在其中一章中，我们描述了如何通过多步**自举(bootstrapping)**方法将蒙特卡洛方法的优点与时序差分算法的优点结合起来。在本书这部分的最后一章中，我们展示了如何将时序差分学习方法与模型学习和计划方法（例如动态规划）相结合，以完整而统一地解决表格强化学习问题。


